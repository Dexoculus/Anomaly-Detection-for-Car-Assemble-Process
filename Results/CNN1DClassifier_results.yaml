records:
-   model_config:
        module: Model
        class: CNN1DClassifier
        args:
            input_dim: 21
            num_classes: 6
    training_config:
        epochs: 50
        learning_rate: 0.001
        optimizer:
            type: Adam
            args:
                weight_decay: 0.0001
        batch_size: 64
    loss_func:
        type: CrossEntropyLoss
        args: {}
    num_parameters: 16838
    total_time: 262.6211714744568
    valid_time: 45.837119579315186
    train_losses:
    - 1.7389489710330963
    - 1.5516341626644135
    - 1.3001470863819122
    - 1.0125577449798584
    - 0.8042504191398621
    - 0.717443123459816
    - 0.6968149244785309
    - 0.6883427798748016
    - 0.6836084872484207
    - 0.6873583495616913
    - 0.6702716499567032
    - 0.6736292243003845
    - 0.6674781888723373
    - 0.6613675206899643
    - 0.6542951315641403
    - 0.6581579446792603
    - 0.6459971368312836
    - 0.638740211725235
    - 0.6347802132368088
    - 0.6274350583553314
    - 0.6200035661458969
    - 0.608637124300003
    - 0.5980679094791412
    - 0.5872162580490112
    - 0.5777583867311478
    - 0.5689519941806793
    - 0.5625612884759903
    - 0.5494007021188736
    - 0.5449119955301285
    - 0.5310224667191505
    - 0.5227038487792015
    - 0.514109805226326
    - 0.4998218044638634
    - 0.5016935020685196
    - 0.48496606945991516
    - 0.4863598048686981
    - 0.47578592598438263
    - 0.4662659168243408
    - 0.4570438265800476
    - 0.4485187232494354
    - 0.45014990121126175
    - 0.44076254218816757
    - 0.4347948953509331
    - 0.4294319301843643
    - 0.44571246951818466
    - 0.4288336932659149
    - 0.42021555453538895
    - 0.4150184988975525
    - 0.4134409725666046
    - 0.4160469099879265
    valid_losses:
    - 1.6306945085525513
    - 1.4084450006484985
    - 1.1225978136062622
    - 0.8678467869758606
    - 0.7391785979270935
    - 0.6935964226722717
    - 0.6833345293998718
    - 0.7005282640457153
    - 0.6772904396057129
    - 0.6766533255577087
    - 0.6795409917831421
    - 0.6814748644828796
    - 0.6654267311096191
    - 0.66164630651474
    - 0.6630421280860901
    - 0.655305027961731
    - 0.6498115658760071
    - 0.6505575776100159
    - 0.6536611914634705
    - 0.634581983089447
    - 0.6335703730583191
    - 0.6243943572044373
    - 0.6170985698699951
    - 0.6137452721595764
    - 0.6029180884361267
    - 0.6011250615119934
    - 0.5919646620750427
    - 0.5828940272331238
    - 0.5866143703460693
    - 0.5704613327980042
    - 0.5687249302864075
    - 0.5654890537261963
    - 0.5523003339767456
    - 0.5630508661270142
    - 0.5383283495903015
    - 0.5410774350166321
    - 0.5325800776481628
    - 0.5187415480613708
    - 0.5167191624641418
    - 0.5094539523124695
    - 0.50266033411026
    - 0.5077565312385559
    - 0.49412477016448975
    - 0.4996759295463562
    - 0.4792914390563965
    - 0.4752848744392395
    - 0.4738847017288208
    - 0.4704221487045288
    - 0.4647407829761505
    - 0.45629894733428955
    test_results:
        accuracy: 0.8076923076923077
