records:
-   model_config:
        module: Model
        class: TransformerClassifier
        args:
            input_dim: 21
            num_classes: 6
            d_model: 64
            nhead: 4
            num_layers: 2
            dim_feedforward: 128
            dropout: 0.1
    training_config:
        epochs: 50
        learning_rate: 0.001
        optimizer:
            type: Adam
            args:
                weight_decay: 0.0001
        batch_size: 64
    loss_func:
        type: CrossEntropyLoss
        args: {}
    num_parameters: 68742
    total_time: 271.1879279613495
    valid_time: 46.553072452545166
    train_losses:
    - 1.5980427861213684
    - 0.9516318440437317
    - 0.8110368400812149
    - 0.7643100768327713
    - 0.742735356092453
    - 0.7353209555149078
    - 0.7237268388271332
    - 0.715433195233345
    - 0.7110902220010757
    - 0.7098231017589569
    - 0.7054243236780167
    - 0.7020764052867889
    - 0.6981032192707062
    - 0.6974111348390579
    - 0.6903753131628036
    - 0.6974301636219025
    - 0.6951851099729538
    - 0.6777098625898361
    - 0.6793088465929031
    - 0.6709844470024109
    - 0.6744828224182129
    - 0.6361980140209198
    - 0.6136773973703384
    - 0.5589172840118408
    - 0.5675541535019875
    - 0.5192060396075249
    - 0.431921623647213
    - 0.3889874964952469
    - 0.33182620257139206
    - 0.357336089015007
    - 0.28113632276654243
    - 0.26490432024002075
    - 0.21434538066387177
    - 0.19541488960385323
    - 0.20584893599152565
    - 0.259880967438221
    - 0.16517500299960375
    - 0.15152395330369473
    - 0.16465819627046585
    - 0.13757416792213917
    - 0.12922713067382574
    - 0.14059974625706673
    - 0.15028094127774239
    - 0.1539121139794588
    - 0.1379386018961668
    - 0.1051953136920929
    - 0.09418422263115644
    - 0.0935911238193512
    - 0.09483004175126553
    - 0.07422898896038532
    valid_losses:
    - 1.0436841249465942
    - 0.8277385234832764
    - 0.7624275088310242
    - 0.7384748458862305
    - 0.7291160225868225
    - 0.7274964451789856
    - 0.7121791243553162
    - 0.7092145085334778
    - 0.7080545425415039
    - 0.701319694519043
    - 0.7024213075637817
    - 0.698361337184906
    - 0.6948275566101074
    - 0.6898176074028015
    - 0.6924545168876648
    - 0.6848124861717224
    - 0.6779007315635681
    - 0.6990659832954407
    - 0.6729019284248352
    - 0.6716792583465576
    - 0.6310192942619324
    - 0.6055512428283691
    - 0.5687637329101562
    - 0.5865845680236816
    - 0.4989456832408905
    - 0.47085851430892944
    - 0.3979249894618988
    - 0.3936923146247864
    - 0.33626434206962585
    - 0.31422215700149536
    - 0.30683234333992004
    - 0.19035573303699493
    - 0.2040153592824936
    - 0.21892119944095612
    - 0.22676503658294678
    - 0.14679475128650665
    - 0.16957247257232666
    - 0.25707557797431946
    - 0.14524531364440918
    - 0.2873292863368988
    - 0.10500464588403702
    - 0.24014736711978912
    - 0.12803995609283447
    - 0.11865504831075668
    - 0.2400151640176773
    - 0.06790613383054733
    - 0.20482249557971954
    - 0.06561782956123352
    - 0.09644529223442078
    - 0.13933150470256805
    test_results:
        accuracy: 0.9423076923076923
